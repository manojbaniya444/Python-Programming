{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNzVJvCaI8FBzSoRQCa4Q3u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Pytorch tensors and numpy"],"metadata":{"id":"za8n9MvKxaDr"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"otiDvVLkxVGO","executionInfo":{"status":"ok","timestamp":1727948879597,"user_tz":-345,"elapsed":8614,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"outputs":[],"source":["import torch\n","import numpy as np"]},{"cell_type":"code","source":["array = np.arange(1, 10, 1)\n","tensor = torch.from_numpy(array)\n","\n","tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xt_wj4Apxmbt","executionInfo":{"status":"ok","timestamp":1727948879598,"user_tz":-345,"elapsed":7,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"dca60483-ff83-4ac1-abe3-5a0ae49c3fe7"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["tensor.dtype # because default dtype of numpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VYQU8Bj0x21Q","executionInfo":{"status":"ok","timestamp":1727948914526,"user_tz":-345,"elapsed":489,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"d17c72c2-8726-4dec-88d0-095ff3c91963"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.int64"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["tenosr_float_32 =tensor.type(torch.float32)\n","tenosr_float_32.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g6GupVSDyAVl","executionInfo":{"status":"ok","timestamp":1727948932680,"user_tz":-345,"elapsed":476,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"876c6dd2-2950-409e-ae74-89ef2c125316"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.float32"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["## to numpy convert\n","\n","tensor = torch.ones(7)\n","numpy_tensor = tensor.numpy()\n","numpy_tensor, numpy_tensor.dtype # default of pytorch float32"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZh1_nBqyM07","executionInfo":{"status":"ok","timestamp":1727949017942,"user_tz":-345,"elapsed":3,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"59a388ed-1c03-4ca8-e7c4-e1d13f1d284c"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), dtype('float32'))"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["## Random out of Random\n","To reduce the randomness, the concept of random seed is used. There is not true actual randomness, computer is fundamentally deterministic so we can acutally control the random generation.\n","\n","Here we can do by seeding."],"metadata":{"id":"Jo4_nX84yhqn"}},{"cell_type":"code","source":["torch.rand(3,3) # every time random"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cCi99gLUyj3V","executionInfo":{"status":"ok","timestamp":1727949125464,"user_tz":-345,"elapsed":475,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"6b0b4d5a-4335-41b2-ddf2-0470d35acc9c"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3954, 0.9510, 0.8863],\n","        [0.3904, 0.6585, 0.4528],\n","        [0.7644, 0.5164, 0.1296]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["tensor_a = torch.rand(3,3)\n","tensor_b = torch.rand(3,3)\n","\n","print(tensor_a)\n","print(tensor_b)\n","print(tensor_a == tensor_b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SNOPIcHjzFM6","executionInfo":{"status":"ok","timestamp":1727949253552,"user_tz":-345,"elapsed":506,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"60fa06f0-df6b-412a-ac1d-bde45a99ce7f"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.6221, 0.4943, 0.0606],\n","        [0.4257, 0.0725, 0.4112],\n","        [0.6773, 0.4117, 0.5328]])\n","tensor([[0.2928, 0.5701, 0.5578],\n","        [0.9234, 0.7462, 0.8301],\n","        [0.9635, 0.3773, 0.1775]])\n","tensor([[False, False, False],\n","        [False, False, False],\n","        [False, False, False]])\n"]}]},{"cell_type":"code","source":["## seeding: give random seed at first\n","\n","RANDOM_SEED = 2\n","torch.manual_seed(RANDOM_SEED)\n","\n","tensor_a = torch.rand(3,3)\n","tensor_b = torch.rand(3,3)\n","\n","print(tensor_a)\n","print(tensor_b)\n","print(tensor_a == tensor_b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y0aq1CT0zTpG","executionInfo":{"status":"ok","timestamp":1727949336710,"user_tz":-345,"elapsed":489,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"43c65125-ead5-4bc6-da8b-4ec944026823"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.6147, 0.3810, 0.6371],\n","        [0.4745, 0.7136, 0.6190],\n","        [0.4425, 0.0958, 0.6142]])\n","tensor([[0.0573, 0.5657, 0.5332],\n","        [0.3901, 0.9088, 0.5334],\n","        [0.7073, 0.7116, 0.2050]])\n","tensor([[False, False, False],\n","        [False, False, False],\n","        [False, False, False]])\n"]}]},{"cell_type":"code","source":["## Only work the seed for the current cell\n","\n","torch.manual_seed(2)\n","tensor_a = torch.rand(3,3)\n","\n","torch.manual_seed(2)\n","tensor_b = torch.rand(3,3)\n","\n","print(tensor_a)\n","print(tensor_b)\n","print(tensor_a == tensor_b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-NLi4zhgzt6s","executionInfo":{"status":"ok","timestamp":1727949435945,"user_tz":-345,"elapsed":472,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"fb3a9e33-805a-46a4-e6a5-6ae54cb9ff89"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.6147, 0.3810, 0.6371],\n","        [0.4745, 0.7136, 0.6190],\n","        [0.4425, 0.0958, 0.6142]])\n","tensor([[0.6147, 0.3810, 0.6371],\n","        [0.4745, 0.7136, 0.6190],\n","        [0.4425, 0.0958, 0.6142]])\n","tensor([[True, True, True],\n","        [True, True, True],\n","        [True, True, True]])\n"]}]},{"cell_type":"markdown","source":["## Running tenosrs and Pytorch object on the  GPU available and make faster computation.\n","\n","## Device agnostic code.\n","Since pytorch is capable of running compute on GPU or CPU, it is best practice to setup device agnostic code."],"metadata":{"id":"PKyHJjgr0OAj"}},{"cell_type":"code","source":["## Check for GPU available or not\n","\n","torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FFkdp6k91kdD","executionInfo":{"status":"ok","timestamp":1727949878399,"user_tz":-345,"elapsed":510,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"a35262cc-d9b3-4ad8-ba68-c33287f5615a"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["## Setup device agnostic code\n","## Use the GPU if available in the machine\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"W8WEWCr91zGf","executionInfo":{"status":"ok","timestamp":1727949941618,"user_tz":-345,"elapsed":504,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"29f8313c-b023-4107-c7a6-1712b84b3c67"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["## Count number of device\n","\n","torch.cuda.device_count() # 0 if running on CPU"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19rxcT3u19fd","executionInfo":{"status":"ok","timestamp":1727949979544,"user_tz":-345,"elapsed":483,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"593ba83e-6e1b-4c5b-be67-a69cea9287e4"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["## Setting device agnostic code and putting tensors on and off the GPU."],"metadata":{"id":"kp6W-6xp2dnd"}},{"cell_type":"code","source":["# creating a tensor\n","tensor = torch.tensor([1,2,3])\n","\n","# tensor not on GPU\n","print(tensor, tensor.device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q7z7HKK-2iB9","executionInfo":{"status":"ok","timestamp":1727950152921,"user_tz":-345,"elapsed":462,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"b3f665b0-e221-425f-83d2-ef9ba0f1f71c"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3]) cpu\n"]}]},{"cell_type":"code","source":["# moving to the GPU if available\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","tensor_on_gpu = tensor.to(device)\n","tensor_on_gpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"loCK0n9I2vzb","executionInfo":{"status":"ok","timestamp":1727950195856,"user_tz":-345,"elapsed":493,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"ecd15bda-b6d0-43e1-9231-e5866d0e017c"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3])"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["## We will get error if running on CPU and use cuda for the GPU\n","\n","# tensor_gpu = torch.tensor([1,2,3], device = \"cuda\")\n","# tensor_gpu\n","\n","# RuntimeError                              Traceback (most recent call last)\n","# <ipython-input-27-a213ad52e5cf> in <cell line: 1>()\n","# ----> 1 tensor_gpu = torch.tensor([1,2,3], device = \"cuda\")\n","#       2 tensor_gpu\n","\n","# /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py in _lazy_init()\n","#     312         if \"CUDA_MODULE_LOADING\" not in os.environ:\n","#     313             os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n","# --> 314         torch._C._cuda_init()\n","#     315         # Some of the queued calls may reentrantly call _lazy_init();\n","#     316         # we need to just return without initializing in that case.\n","\n","# RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"],"metadata":{"id":"tHs08XOq2-cs","executionInfo":{"status":"ok","timestamp":1727950285984,"user_tz":-345,"elapsed":467,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["## Moving tensor back to CPU\n","\n","tensor_back_on_cpu = tensor_on_gpu.cpu().numpy() # fist convert to CPU and to numpy\n","tensor_back_on_cpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1vftk_e3Orv","executionInfo":{"status":"ok","timestamp":1727950410416,"user_tz":-345,"elapsed":460,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"4250909f-436a-417f-e268-b6269b516a4a"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 2, 3])"]},"metadata":{},"execution_count":33}]}]}