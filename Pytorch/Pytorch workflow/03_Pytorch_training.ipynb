{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full training pipeline of Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\n",
    "    columns=[\"id\", \"Unnamed: 32\"],\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    df.drop(columns=[\"diagnosis\"]),\n",
    "    df[\"diagnosis\"],\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>14.480</td>\n",
       "      <td>21.46</td>\n",
       "      <td>94.25</td>\n",
       "      <td>648.2</td>\n",
       "      <td>0.09444</td>\n",
       "      <td>0.09947</td>\n",
       "      <td>0.12040</td>\n",
       "      <td>0.04938</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.05636</td>\n",
       "      <td>...</td>\n",
       "      <td>16.210</td>\n",
       "      <td>29.25</td>\n",
       "      <td>108.40</td>\n",
       "      <td>808.9</td>\n",
       "      <td>0.13060</td>\n",
       "      <td>0.19760</td>\n",
       "      <td>0.3349</td>\n",
       "      <td>0.12250</td>\n",
       "      <td>0.3020</td>\n",
       "      <td>0.06846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>12.860</td>\n",
       "      <td>18.00</td>\n",
       "      <td>83.19</td>\n",
       "      <td>506.3</td>\n",
       "      <td>0.09934</td>\n",
       "      <td>0.09546</td>\n",
       "      <td>0.03889</td>\n",
       "      <td>0.02315</td>\n",
       "      <td>0.1718</td>\n",
       "      <td>0.05997</td>\n",
       "      <td>...</td>\n",
       "      <td>14.240</td>\n",
       "      <td>24.82</td>\n",
       "      <td>91.88</td>\n",
       "      <td>622.1</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>0.21410</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2779</td>\n",
       "      <td>0.07918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>11.410</td>\n",
       "      <td>10.82</td>\n",
       "      <td>73.34</td>\n",
       "      <td>403.3</td>\n",
       "      <td>0.09373</td>\n",
       "      <td>0.06685</td>\n",
       "      <td>0.03512</td>\n",
       "      <td>0.02623</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.06113</td>\n",
       "      <td>...</td>\n",
       "      <td>12.820</td>\n",
       "      <td>15.97</td>\n",
       "      <td>83.74</td>\n",
       "      <td>510.5</td>\n",
       "      <td>0.15480</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.08958</td>\n",
       "      <td>0.3016</td>\n",
       "      <td>0.08523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>8.671</td>\n",
       "      <td>14.45</td>\n",
       "      <td>54.42</td>\n",
       "      <td>227.2</td>\n",
       "      <td>0.09138</td>\n",
       "      <td>0.04276</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1722</td>\n",
       "      <td>0.06724</td>\n",
       "      <td>...</td>\n",
       "      <td>9.262</td>\n",
       "      <td>17.04</td>\n",
       "      <td>58.36</td>\n",
       "      <td>259.2</td>\n",
       "      <td>0.11620</td>\n",
       "      <td>0.07057</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2592</td>\n",
       "      <td>0.07848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>13.640</td>\n",
       "      <td>16.34</td>\n",
       "      <td>87.21</td>\n",
       "      <td>571.8</td>\n",
       "      <td>0.07685</td>\n",
       "      <td>0.06059</td>\n",
       "      <td>0.01857</td>\n",
       "      <td>0.01723</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.05953</td>\n",
       "      <td>...</td>\n",
       "      <td>14.670</td>\n",
       "      <td>23.19</td>\n",
       "      <td>96.08</td>\n",
       "      <td>656.7</td>\n",
       "      <td>0.10890</td>\n",
       "      <td>0.15820</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.08586</td>\n",
       "      <td>0.2346</td>\n",
       "      <td>0.08025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>10.650</td>\n",
       "      <td>25.22</td>\n",
       "      <td>68.01</td>\n",
       "      <td>347.0</td>\n",
       "      <td>0.09657</td>\n",
       "      <td>0.07234</td>\n",
       "      <td>0.02379</td>\n",
       "      <td>0.01615</td>\n",
       "      <td>0.1897</td>\n",
       "      <td>0.06329</td>\n",
       "      <td>...</td>\n",
       "      <td>12.250</td>\n",
       "      <td>35.19</td>\n",
       "      <td>77.98</td>\n",
       "      <td>455.7</td>\n",
       "      <td>0.14990</td>\n",
       "      <td>0.13980</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.06136</td>\n",
       "      <td>0.3409</td>\n",
       "      <td>0.08147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>12.050</td>\n",
       "      <td>22.72</td>\n",
       "      <td>78.75</td>\n",
       "      <td>447.8</td>\n",
       "      <td>0.06935</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.07943</td>\n",
       "      <td>0.02978</td>\n",
       "      <td>0.1203</td>\n",
       "      <td>0.06659</td>\n",
       "      <td>...</td>\n",
       "      <td>12.570</td>\n",
       "      <td>28.71</td>\n",
       "      <td>87.36</td>\n",
       "      <td>488.4</td>\n",
       "      <td>0.08799</td>\n",
       "      <td>0.32140</td>\n",
       "      <td>0.2912</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.09349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>16.350</td>\n",
       "      <td>23.29</td>\n",
       "      <td>109.00</td>\n",
       "      <td>840.4</td>\n",
       "      <td>0.09742</td>\n",
       "      <td>0.14970</td>\n",
       "      <td>0.18110</td>\n",
       "      <td>0.08773</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.06218</td>\n",
       "      <td>...</td>\n",
       "      <td>19.380</td>\n",
       "      <td>31.03</td>\n",
       "      <td>129.30</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>0.14150</td>\n",
       "      <td>0.46650</td>\n",
       "      <td>0.7087</td>\n",
       "      <td>0.22480</td>\n",
       "      <td>0.4824</td>\n",
       "      <td>0.09614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>11.930</td>\n",
       "      <td>10.91</td>\n",
       "      <td>76.14</td>\n",
       "      <td>442.7</td>\n",
       "      <td>0.08872</td>\n",
       "      <td>0.05242</td>\n",
       "      <td>0.02606</td>\n",
       "      <td>0.01796</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.05541</td>\n",
       "      <td>...</td>\n",
       "      <td>13.800</td>\n",
       "      <td>20.14</td>\n",
       "      <td>87.64</td>\n",
       "      <td>589.5</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.15750</td>\n",
       "      <td>0.1514</td>\n",
       "      <td>0.06876</td>\n",
       "      <td>0.2460</td>\n",
       "      <td>0.07262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>15.460</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.80</td>\n",
       "      <td>731.3</td>\n",
       "      <td>0.11830</td>\n",
       "      <td>0.18700</td>\n",
       "      <td>0.20300</td>\n",
       "      <td>0.08520</td>\n",
       "      <td>0.1807</td>\n",
       "      <td>0.07083</td>\n",
       "      <td>...</td>\n",
       "      <td>17.110</td>\n",
       "      <td>36.33</td>\n",
       "      <td>117.70</td>\n",
       "      <td>909.4</td>\n",
       "      <td>0.17320</td>\n",
       "      <td>0.49670</td>\n",
       "      <td>0.5911</td>\n",
       "      <td>0.21630</td>\n",
       "      <td>0.3013</td>\n",
       "      <td>0.10670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "86        14.480         21.46           94.25      648.2          0.09444   \n",
       "79        12.860         18.00           83.19      506.3          0.09934   \n",
       "120       11.410         10.82           73.34      403.3          0.09373   \n",
       "175        8.671         14.45           54.42      227.2          0.09138   \n",
       "51        13.640         16.34           87.21      571.8          0.07685   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "248       10.650         25.22           68.01      347.0          0.09657   \n",
       "382       12.050         22.72           78.75      447.8          0.06935   \n",
       "370       16.350         23.29          109.00      840.4          0.09742   \n",
       "401       11.930         10.91           76.14      442.7          0.08872   \n",
       "509       15.460         23.95          103.80      731.3          0.11830   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "86            0.09947         0.12040              0.04938         0.2075   \n",
       "79            0.09546         0.03889              0.02315         0.1718   \n",
       "120           0.06685         0.03512              0.02623         0.1667   \n",
       "175           0.04276         0.00000              0.00000         0.1722   \n",
       "51            0.06059         0.01857              0.01723         0.1353   \n",
       "..                ...             ...                  ...            ...   \n",
       "248           0.07234         0.02379              0.01615         0.1897   \n",
       "382           0.10730         0.07943              0.02978         0.1203   \n",
       "370           0.14970         0.18110              0.08773         0.2175   \n",
       "401           0.05242         0.02606              0.01796         0.1601   \n",
       "509           0.18700         0.20300              0.08520         0.1807   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "86                  0.05636  ...        16.210          29.25   \n",
       "79                  0.05997  ...        14.240          24.82   \n",
       "120                 0.06113  ...        12.820          15.97   \n",
       "175                 0.06724  ...         9.262          17.04   \n",
       "51                  0.05953  ...        14.670          23.19   \n",
       "..                      ...  ...           ...            ...   \n",
       "248                 0.06329  ...        12.250          35.19   \n",
       "382                 0.06659  ...        12.570          28.71   \n",
       "370                 0.06218  ...        19.380          31.03   \n",
       "401                 0.05541  ...        13.800          20.14   \n",
       "509                 0.07083  ...        17.110          36.33   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "86            108.40       808.9           0.13060            0.19760   \n",
       "79             91.88       622.1           0.12890            0.21410   \n",
       "120            83.74       510.5           0.15480            0.23900   \n",
       "175            58.36       259.2           0.11620            0.07057   \n",
       "51             96.08       656.7           0.10890            0.15820   \n",
       "..               ...         ...               ...                ...   \n",
       "248            77.98       455.7           0.14990            0.13980   \n",
       "382            87.36       488.4           0.08799            0.32140   \n",
       "370           129.30      1165.0           0.14150            0.46650   \n",
       "401            87.64       589.5           0.13740            0.15750   \n",
       "509           117.70       909.4           0.17320            0.49670   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "86            0.3349               0.12250          0.3020   \n",
       "79            0.1731               0.07926          0.2779   \n",
       "120           0.2102               0.08958          0.3016   \n",
       "175           0.0000               0.00000          0.2592   \n",
       "51            0.1050               0.08586          0.2346   \n",
       "..               ...                   ...             ...   \n",
       "248           0.1125               0.06136          0.3409   \n",
       "382           0.2912               0.10920          0.2191   \n",
       "370           0.7087               0.22480          0.4824   \n",
       "401           0.1514               0.06876          0.2460   \n",
       "509           0.5911               0.21630          0.3013   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "86                   0.06846  \n",
       "79                   0.07918  \n",
       "120                  0.08523  \n",
       "175                  0.07848  \n",
       "51                   0.08025  \n",
       "..                       ...  \n",
       "248                  0.08147  \n",
       "382                  0.09349  \n",
       "370                  0.09614  \n",
       "401                  0.07262  \n",
       "509                  0.10670  \n",
       "\n",
       "[455 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30), (455,), (114,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train)\n",
    "X_test_tensor = torch.from_numpy(X_test)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "y_test_tensor = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNetwork():\n",
    "    def __init__(self, X):\n",
    "        self.weights = torch.rand(X.shape[1], 1, dtype=torch.float64, requires_grad=True)\n",
    "        self.bias = torch.rand(1, dtype=torch.float64, requires_grad=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = torch.matmul(x, self.weights) + self.bias # (1, 31).(31,1)+(1)=(1,1) # (100, 31).(31, 1) + (1) = (100, 1) for all 100 data sample\n",
    "        y_pred = torch.sigmoid(z)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyNeuralNetwork(X_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30, 1]), torch.Size([1]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights.shape, model.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_parameters = len(model.weights.squeeze()) + len(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total model parameter is: 31\n"
     ]
    }
   ],
   "source": [
    "print(f\"The total model parameter is: {total_parameters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with custom pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor.unsqueeze(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.5183351626930917\n",
      "Epoch: 10, Loss: 0.5010111072822057\n",
      "Epoch: 20, Loss: 0.4842969684839006\n",
      "Epoch: 30, Loss: 0.46816796995390086\n",
      "Epoch: 40, Loss: 0.4526014995648131\n",
      "Epoch: 50, Loss: 0.43757709364155667\n",
      "Epoch: 60, Loss: 0.4230764640734725\n",
      "Epoch: 70, Loss: 0.40908353632990385\n",
      "Epoch: 80, Loss: 0.39558446752728327\n",
      "Epoch: 90, Loss: 0.3825675680337671\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model_0 = MyNeuralNetwork(X_train_tensor)\n",
    "\n",
    "# define loop\n",
    "for epoch in range(EPOCHS):\n",
    "    # forward propagation\n",
    "    y_pred = model_0.forward(X_train_tensor) # (455, 1)\n",
    "    loss = torch.nn.functional.binary_cross_entropy(\n",
    "        y_pred, # (455, 1)\n",
    "        y_train_tensor.unsqueeze(1).type(torch.float64) # (455, 1)\n",
    "    )\n",
    "    \n",
    "    # backward propagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # update weight\n",
    "    with torch.no_grad():\n",
    "        model_0.weights -= LEARNING_RATE * model_0.weights.grad\n",
    "        model_0.bias -= LEARNING_RATE * model_0.bias.grad\n",
    "        \n",
    "        # zero gradient\n",
    "        model_0.weights.grad.zero_()\n",
    "        model_0.bias.grad.zero_()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Pytorch Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyNeuralNetwork(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(MyNeuralNetwork, self).__init__()\n",
    "        self.linear_1 = nn.Linear(in_features=in_features, out_features=64, bias=True)\n",
    "        self.linear_2 = nn.Linear(in_features=64, out_features=8, bias=True)\n",
    "        self.linear_3 = nn.Linear(in_features=8, out_features=1, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o1 = self.linear_1(x) # (455, 30).(30, 64) = (455, 64)\n",
    "        o2 = self.relu(o1) # (455, 64)\n",
    "        o3 = self.linear_2(o2) # (455, 64).(64, 8) = (455, 8)\n",
    "        o4 = self.linear_3(o3) # (455, 8).(8, 1) = (455, 1)\n",
    "        y = self.sigmoid(o4)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = MyNeuralNetwork(X_train_tensor.shape[1], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNeuralNetwork(\n",
       "  (linear_1): Linear(in_features=30, out_features=64, bias=True)\n",
       "  (linear_2): Linear(in_features=64, out_features=8, bias=True)\n",
       "  (linear_3): Linear(in_features=8, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters in Model 1: 2513\n"
     ]
    }
   ],
   "source": [
    "total_parameters_model_1 = sum(p.numel() for p in model_1.parameters() if p.requires_grad)\n",
    "print(f\"Total Parameters in Model 1: {total_parameters_model_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model_1.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 and Loss: 0.6491639614105225\n",
      "Epoch: 11 and Loss: 0.6277534365653992\n",
      "Epoch: 21 and Loss: 0.6062805652618408\n",
      "Epoch: 31 and Loss: 0.5844565033912659\n",
      "Epoch: 41 and Loss: 0.5621252059936523\n",
      "Epoch: 51 and Loss: 0.539228618144989\n",
      "Epoch: 61 and Loss: 0.5157952308654785\n",
      "Epoch: 71 and Loss: 0.4919372797012329\n",
      "Epoch: 81 and Loss: 0.4678674638271332\n",
      "Epoch: 91 and Loss: 0.443827360868454\n",
      "Epoch: 100 and Loss: 0.4224514365196228\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    # forward propagation\n",
    "    y_pred = model_1(X_train_tensor.float())\n",
    "    loss = criterion(\n",
    "        y_pred,\n",
    "        y_train_tensor.unsqueeze(1).float() # (455) : (455, 1) to match the shape of prediction\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0 or epoch == EPOCHS - 1:\n",
    "        print(f\"Epoch: {epoch + 1} and Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training in Batches with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x15ac5faa930>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = data_utils.TensorDataset(X_train_tensor, y_train_tensor.unsqueeze(1))\n",
    "\n",
    "train_loader = data_utils.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 30]), torch.Size([8, 1]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].shape, next(iter(train_loader))[1].shape # batch of 8 sample with 30 features and 1 target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear_1 = nn.Linear(in_features=in_features, out_features=1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o1 = self.linear_1(x) # (455, 30).(30, 64) = (455, 64)\n",
    "        y = self.sigmoid(o1)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNeuralNetwork(\n",
       "  (linear_1): Linear(in_features=30, out_features=64, bias=True)\n",
       "  (linear_2): Linear(in_features=64, out_features=8, bias=True)\n",
       "  (linear_3): Linear(in_features=8, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Model(X_train_tensor.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (linear_1): Linear(in_features=30, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_2.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 12.9394\n",
      "Epoch: 10, Loss: 3.4155\n",
      "Epoch: 20, Loss: 3.0241\n",
      "Epoch: 30, Loss: 2.7996\n",
      "Epoch: 40, Loss: 2.6739\n",
      "Epoch: 50, Loss: 2.6375\n",
      "Epoch: 60, Loss: 2.5207\n",
      "Epoch: 70, Loss: 2.5394\n",
      "Epoch: 80, Loss: 2.3724\n",
      "Epoch: 90, Loss: 2.3803\n",
      "Epoch: 99, Loss: 2.3011\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0 \n",
    "\n",
    "    for batch in train_loader:\n",
    "        X_batch, y_batch = batch\n",
    "        \n",
    "        # Forward propagation\n",
    "        y_pred = model_2(X_batch.float())\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(\n",
    "            y_pred, # (8, 1)\n",
    "            y_batch.float() # (8, 1)\n",
    "        )\n",
    "        \n",
    "        # Backward propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Zero gradients for the next batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Accumulate total loss for the epoch\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Logging at every 10th epoch or the last epoch\n",
    "    if epoch % 10 == 0 or epoch == EPOCHS - 1:\n",
    "        print(f\"Epoch: {epoch}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve the model accuracy by changing the hyperparameter of the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
